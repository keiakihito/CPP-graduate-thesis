  Extracted Claims

  1. Role of Audio Embeddings
  • Quote: "As a result, learned audio representations now form
     the backbone of many content-based music retrieval systems
     \cite{tamm2024}."
  • Cited Paper(s): Tamm et al. (2024)
  • Core Claim: Learned audio embeddings are the fundamental
    component of modern content-based music retrieval.

  # 2. Compact CNN Effectiveness ✅
  ## => revise claim
  • Quote: "Compact CNN architectures have been shown to 
    provide efficient and effective embeddings for 
    music-related tasks \cite{reddy2022}."
  • Cited Paper(s): Reddy et al. (2022)
  • Core Claim: Small, efficient CNNs can still produce
    high-quality embeddings for music tasks.

  # 3. CNN Performance vs. Complexity ✅ 
  ## => revise the claim
  • Quote: "Several studies evaluate CNN-based embeddings using
     supervised objectives, such as genre or tag 
    classification, demonstrating strong performance with 
    relatively modest model complexity \cite{dias_cnn, 
    zhang2022}."
  • Cited Paper(s): Dias et al.; Zhang et al. (2022)
  • Core Claim: CNNs achieve high classification accuracy even
    with low model complexity.

  4. Temporal Modeling in Hybrids
  • Quote: "Hybrid CNN--RNN architectures have been applied to 
    tasks such as emotion recognition and music classification,
     where temporal dynamics play an important role 
    \cite{lin2024}."
  • Cited Paper(s): Lin et al. (2024)
  • Core Claim: Combining CNNs with RNNs helps model temporal
    dynamics for tasks like emotion recognition.

  5. Transformer Architectures
  • Quote: "CNN--Transformer hybrids combine convolutional 
    front-ends with transformer encoders to model global 
    temporal relationships, while pure transformer-based models
     operate directly on spectrogram patches or learned audio 
    tokens\cite{pourmoazemi2024}."
  • Cited Paper(s): Pourmoazemi et al. (2024)
  • Core Claim: Recent architectures use Transformers (either
    hybrid or pure) to capture global temporal relationships in
     audio.

  # 6. Transformer Performance ✅ 
  ## => Replace with gong
  • Quote: "Models such as Audio Spectrogram Transformer (AST) 
    demonstrate that transformer-based embeddings can achieve 
    strong performance across a variety of audio tasks 
    \cite{ramos_ssl}."
  • Cited Paper(s): Ramos et al.
  • Core Claim: Transformer-based models like AST achieve
    strong performance across diverse audio tasks.

  ## 7. Diversity in Recommendation ✅
  ## => Revise the claim
  • Quote: "Diversity-aware evaluation emphasizes the ability 
    of a system to surface varied and less popular items, which
     is particularly relevant for cultural and archival 
    collections \cite{porcaro2022}."
  • Cited Paper(s): Porcaro et al. (2022)
  • Core Claim: Evaluating recommendation diversity is crucial
    for cultural archives to ensure less popular items are
    discovered.

  8. User Modeling Context
  • Quote: "A parallel line of research focuses on modeling 
    user behavior, preferences, and context to improve 
    recommendation quality \cite{lin2025}."
  • Cited Paper(s): Lin et al. (2025)
  • Core Claim: User modeling is a distinct research stream
    focused on improving recommendation quality via behavioral
    data.

  9. Personalization Approaches
  • Quote: "Sequential recommendation models, emotion-aware 
    systems, and geographically informed approaches incorporate
     user interaction data to personalize recommendations 
    \cite{abbattista2024, schedl2021}."
  • Cited Paper(s): Abbattista et al. (2024); Schedl et al.
    (2021)
  • Core Claim: Modern systems use interaction data for complex
     personalization strategies like emotion-aware or
    sequential recommendation.

  10. System Scalability
  • Quote: "These studies address challenges related to 
    latency, scalability, and system integration 
    \cite{prasad_music}."
  • Cited Paper(s): Prasad et al.
  • Core Claim: Research on system architecture focuses on
    engineering challenges like latency and scalability.