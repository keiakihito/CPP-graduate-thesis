# 📋 Work Log — 2025-08-22

# ✨ Meeting

1.ChatGPT論文作成を読み終わる。IEEE形式の出力が参考になった。論文を打ち込んで解説してもらう。
2.GPTに Schedl's paper and find potential citationを説明してもらう。

i. Neural models for music representation
- Schedl explains that DL is increasingly used to extract latent factors from audio signals and metadata.
- This supports your hypotheses H1 (pretrained embeddings) and H2 (CRNN > CNN), because the paper frames CNNs and sequence-aware models (RNN/CRNN) as central to content-based and sequential music recommendation.

ii. Sequential modeling of music
- The paper highlights RNN-based approaches for automatic playlist continuation and next-track prediction.
- This provides theoretical grounding for your claim that CRNNs better capture temporal flow in classical recordings.

iii.Hybrid approaches and challenges
- Schedl discusses hybrid recommendation (integrating content and collaborative filtering).
- While he doesn’t focus on diversity/metadata re-ranking like you propose, you can position your hybrid re-ranking as addressing one of the open challenges he identifies: balancing system-centric accuracy with user-centric satisfaction.

# Where You Should Cite Schedl (2019)
## Background / Literature Review
- When introducing why DL matters in music recommendation:
“Deep neural networks are widely used for extracting latent item factors from audio and metadata, and for modeling sequential listening patterns in music recommender systems (Schedl, 2019).”

## Model Justification (CNN vs CRNN vs Pretrained)
- For CNN: cite his discussion of early CNNs on spectrograms.
- For CRNN: cite his coverage of RNN/sequence-aware approaches.
- For pretrained embeddings: connect to his observation that feature learning from audio is central to deep MRS, but large datasets are usually required.

## Evaluation Metrics Section
- When describing metrics like Precision@K, Recall@K, MAP, NDCG, cite Schedl’s Table 2 (page 3–4), which explicitly defines these measures.

## Framing Your Contribution
- In the conclusion or contribution section, cite his “Current Challenges” section (page 7–8), especially:
• the lack of standardized datasets,
• the need for beyond-accuracy evaluation, and
•the system-centric vs user-centric gap
- This gives you a way to say: “Our hybrid re-ranking directly addresses user-centric quality, a challenge noted by Schedl (2019).”

When introducing why DL matters in music recommendation:
“Deep neural networks are widely used for extracting latent item factors from audio and metadata, and for modeling sequential listening patterns in music recommender systems (Schedl, 2019).”


Action plan
1. 実際のSchedlを読む。
2. zetroのシェアをお願いする。